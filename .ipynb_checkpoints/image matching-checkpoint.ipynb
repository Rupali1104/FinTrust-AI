{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32506002-faf9-44e4-a49f-bb1f617a1565",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install opencv-python-headless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ff74ab-70f7-49a2-9372-da59ae5acec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the images\n",
    "img1 = cv2.imread('1.jpg', cv2.IMREAD_GRAYSCALE)  # Query image\n",
    "img2 = cv2.imread('1.jpg', cv2.IMREAD_GRAYSCALE)  # Train image\n",
    "\n",
    "# Initialize ORB detector (or use SIFT if you have access to the opencv_contrib package)\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Find the keypoints and descriptors with ORB\n",
    "kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "# Create a brute force matcher\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# Match descriptors\n",
    "matches = bf.match(des1, des2)\n",
    "\n",
    "# Sort them in ascending order of distance\n",
    "matches = sorted(matches, key = lambda x: x.distance)\n",
    "\n",
    "# Draw the matches\n",
    "img_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches[:10], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# Show the result\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(img_matches)\n",
    "plt.title('Image Matching')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983ced61-8605-48ff-b1be-e029c94b3536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import Tk, filedialog  # Ensure this line is included\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc6cecb-38f6-4946-b342-29580fc6d382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834909b4-b996-457e-b30e-5df7dce7cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tkinter import Tk, filedialog\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "\n",
    "# Define the base model (e.g., CNN with Conv2D layers)\n",
    "def create_base_model(input_shape):\n",
    "    base_input = layers.Input(input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(base_input)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    return Model(base_input, x)\n",
    "\n",
    "# Define the Siamese network architecture\n",
    "def create_siamese_model(input_shape):\n",
    "    base_model = create_base_model(input_shape)\n",
    "    input_1 = layers.Input(input_shape)\n",
    "    input_2 = layers.Input(input_shape)\n",
    "\n",
    "    # Generate the embeddings for both inputs\n",
    "    embedding_1 = base_model(input_1)\n",
    "    embedding_2 = base_model(input_2)\n",
    "\n",
    "    # Compute the distance between the two embeddings\n",
    "    distance = layers.Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))([embedding_1, embedding_2])\n",
    "    distance = layers.Dense(1, activation=\"sigmoid\")(distance)  # Output similarity score\n",
    "\n",
    "    return Model([input_1, input_2], distance)\n",
    "\n",
    "# Preprocess the images: Resize, normalize, and expand the dimensions\n",
    "def preprocess_data(img_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(100, 100))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = img / 255.0  # Normalize the images\n",
    "    return img\n",
    "\n",
    "# Function to open a file dialog for uploading images\n",
    "def upload_image():\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Hide the main tkinter window\n",
    "    file_path = filedialog.askopenfilename(title=\"Select an Image\", filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "    root.destroy()  # Close the tkinter window\n",
    "    return file_path\n",
    "\n",
    "# Load and preprocess all images\n",
    "img1 = preprocess_data(\"1.jpg\")\n",
    "img2 = preprocess_data(\"2.jpg\")\n",
    "img3 = preprocess_data(\"3.jpg\")\n",
    "img4 = preprocess_data(\"4.jpg\")\n",
    "img5 = preprocess_data(\"5.jpg\")\n",
    "img6 = preprocess_data(\"6.jpg\")\n",
    "img7 = preprocess_data(\"7.jpg\")\n",
    "img8 = preprocess_data(\"8.jpg\")\n",
    "img9 = preprocess_data(\"9.jpg\")\n",
    "img10 = preprocess_data(\"10.jpg\")\n",
    "img11 = preprocess_data(\"11.jpg\")\n",
    "img12 = preprocess_data(\"12.jpg\")\n",
    "img13 = preprocess_data(\"13.jpg\")\n",
    "img14 = preprocess_data(\"14.jpg\")\n",
    "img15 = preprocess_data(\"15.jpg\")\n",
    "img16 = preprocess_data(\"16.jpg\")\n",
    "img17 = preprocess_data(\"17.jpg\")\n",
    "img18 = preprocess_data(\"18.jpg\")\n",
    "\n",
    "# Create image pairs and labels\n",
    "image_pairs = [\n",
    "    (img1, img2), (img3, img4), (img5, img6), (img7, img8), \n",
    "    (img9, img10), (img11, img12), (img13, img14), (img15, img16), (img17, img18)\n",
    "]\n",
    "y_train = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1])  # Labels for each pair\n",
    "\n",
    "# Separate image pairs into two arrays\n",
    "X_train_1 = np.array([pair[0] for pair in image_pairs])\n",
    "X_train_2 = np.array([pair[1] for pair in image_pairs])\n",
    "\n",
    "# Define input shape\n",
    "input_shape = (100, 100, 3)\n",
    "\n",
    "# Instantiate the model\n",
    "siamese_model = create_siamese_model(input_shape)\n",
    "siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "siamese_model.fit([X_train_1, X_train_2], y_train, epochs=20, batch_size=32)\n",
    "\n",
    "\n",
    "# Perform matching with an uploaded image\n",
    "print(\"Upload an image to match:\")\n",
    "uploaded_img_path = upload_image()\n",
    "if uploaded_img_path:\n",
    "    uploaded_img = preprocess_data(uploaded_img_path)\n",
    "    uploaded_img = np.expand_dims(uploaded_img, axis=0)\n",
    "\n",
    "    # Find the best match\n",
    "    highest_similarity = 0\n",
    "    matched_idx = None\n",
    "    for idx, img in enumerate([img1, img3, img5, img7, img9, img11, img13, img15, img17]):\n",
    "        similarity_score = siamese_model.predict([np.expand_dims(img, axis=0), uploaded_img])[0][0]\n",
    "        if similarity_score > highest_similarity:\n",
    "            highest_similarity = similarity_score\n",
    "            matched_idx = idx\n",
    "# Print the result\n",
    "    if highest_similarity >= 0.5:\n",
    "        print(f\"Match found! Similarity Score: {highest_similarity}\")\n",
    "    else:\n",
    "        print(f\"No match found. Similarity Score: {highest_similarity}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd1300a-143e-440b-8d64-c19fbbf2afc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming 'uploaded_img' is your loaded image\n",
    "plt.figure(figsize=(2, 2), dpi=100)  # Reduce figure size, increase DPI for better resolution\n",
    "plt.imshow(tf.keras.preprocessing.image.array_to_img(uploaded_img[0]), interpolation='nearest')  # Use 'nearest' for clear pixels\n",
    "plt.title(\"match found!!!\")\n",
    "plt.axis(\"off\")  # Remove axes for a cleaner display\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041216fb-80c7-4ad2-8d86-18d9f1e9bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_uploaded_image(uploaded_img_path):\n",
    "    # Open the uploaded image using PIL and display at a larger size\n",
    "    img = Image.open(uploaded_img_path)\n",
    "    img = img.resize((600, 600), Image.ANTIALIAS)  # Resize to a larger size for clarity\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Uploaded Image\")\n",
    "    plt.axis(\"off\")  # Hide axes for clean display\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5869420d-9407-4a0b-841d-927edecfa87c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
